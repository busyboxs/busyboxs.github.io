<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>使用 PaddleHub 实现有趣的图像效果 | Busyboxs</title><meta name="keywords" content="cpp"><meta name="author" content="Busyboxs"><meta name="copyright" content="Busyboxs"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="提起短视频，应该没有人不知道吧。现在基本上到处都能看得见有人拿着手机在刷短视频。我也玩过短视频，当我在玩短视频时，也尝试了应用里面的一些特效和道具，感觉很有趣。于是我就想着能不能自己尝试着做出这些效果呢？这些特效很多都和图像处理相关，例如人脸检测、人脸关键点检测，语义分割等等。如果是自己去训练模型来实现这些特效感觉会很麻烦，幸好遇见了 PaddleHub，可以直接使用一些训练好的模型，因此实现这些">
<meta property="og:type" content="article">
<meta property="og:title" content="使用 PaddleHub 实现有趣的图像效果">
<meta property="og:url" content="https://busyboxs.github.io/blogs/98b64d33/index.html">
<meta property="og:site_name" content="Busyboxs">
<meta property="og:description" content="提起短视频，应该没有人不知道吧。现在基本上到处都能看得见有人拿着手机在刷短视频。我也玩过短视频，当我在玩短视频时，也尝试了应用里面的一些特效和道具，感觉很有趣。于是我就想着能不能自己尝试着做出这些效果呢？这些特效很多都和图像处理相关，例如人脸检测、人脸关键点检测，语义分割等等。如果是自己去训练模型来实现这些特效感觉会很麻烦，幸好遇见了 PaddleHub，可以直接使用一些训练好的模型，因此实现这些">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png">
<meta property="article:published_time" content="2020-05-08T14:04:33.000Z">
<meta property="article:modified_time" content="2020-06-21T02:40:46.404Z">
<meta property="article:author" content="Busyboxs">
<meta property="article:tag" content="cpp">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://busyboxs.github.io/blogs/98b64d33/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google_site_verification" content="FwkuU16DW0uUtLvBlI63aK9-eCBhC55pVQMscORY34M"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?0737f86b9c26e7c4269a4dec38cea0c8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-158970947-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-158970947-1');
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lacquer&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '使用 PaddleHub 实现有趣的图像效果',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-06-21 10:40:46'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">92</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/img/archive_img.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Busyboxs</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">使用 PaddleHub 实现有趣的图像效果</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-05-08T14:04:33.000Z" title="发表于 2020-05-08 22:04:33">2020-05-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-06-21T02:40:46.404Z" title="更新于 2020-06-21 10:40:46">2020-06-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cpp/">cpp</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="使用 PaddleHub 实现有趣的图像效果"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>提起短视频，应该没有人不知道吧。现在基本上到处都能看得见有人拿着手机在刷短视频。我也玩过短视频，当我在玩短视频时，也尝试了应用里面的一些特效和道具，感觉很有趣。于是我就想着能不能自己尝试着做出这些效果呢？这些特效很多都和图像处理相关，例如人脸检测、人脸关键点检测，语义分割等等。如果是自己去训练模型来实现这些特效感觉会很麻烦，幸好遇见了 PaddleHub，可以直接使用一些训练好的模型，因此实现这些特效变得简单得多。</p>
<p>接下来，本篇文章将介绍如何使用 PaddleHub 来实现以下效果：</p>
<ul>
<li>变换人体部分的颜色</li>
<li>人脸贴纸效果</li>
<li>更换视频背景</li>
</ul>
<hr>
<h2 id="PaddleHub-介绍"><a href="#PaddleHub-介绍" class="headerlink" title="PaddleHub 介绍"></a>PaddleHub 介绍</h2><p>PaddleHub 便捷地获取 PaddlePaddle 生态下的预训练模型，完成模型的管理和一键预测。配合使用 Fine-tune API，可以基于大规模预训练模型快速完成迁移学习，让预训练模型能更好地服务于用户特定场景的应用。</p>
<p>PaddleHub 有许多学习模型，包括文本、图像和视频。想要了解更多关于 PaddleHub 的内容请访问 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/hub">PaddleHub 官方网站</a>。</p>
<h2 id="Part1-变换人体部分的颜色"><a href="#Part1-变换人体部分的颜色" class="headerlink" title="Part1. 变换人体部分的颜色"></a>Part1. 变换人体部分的颜色</h2><blockquote>
<p>注：由于现在人体解析模型的接口已经更新到 1.1.0 版本，接口发生了变化，该代码仅支持 1.0.0 版本，需要使用下面安装代码进行安装</p>
<p>$ <code>hub install ace2p==1.0.0</code></p>
</blockquote>
<p>在 PaddleHub 学习模型中，有一个人体解析的模型，ace2p。人体解析是细粒度的语义分割任务，其旨在识别像素级别的人类图像的组成部分（例如，身体部位和服装）。该模型将人体分为 20 个部分，包括头、头发、左手、右手、上衣、裤子等等。更多的内容可以参考<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/hubdetail?name=ace2p&amp;en_category=ImageSegmentation">官方模型介绍</a>。</p>
<p>这里我只实现了头发和上衣颜色的改变，其他部分原理相同。接下来开始具体实现代码的介绍：</p>
<p>首先，导入相关库，由于需要使用到 PaddleHub 中的模型，首先需要导入 <code>paddlehub</code> 库，同时为了更方便地进行图像处理，我这里使用了 opencv 库。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>
<p>然后如 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/hubdetail?name=ace2p&amp;en_category=ImageSegmentation">ace2p 官方模型</a>中介绍的那样调用 PaddleHub 检测出给定图像的人体部分，这里我使用的给定图像如下所示，该图像只有人体的上半身，我这里想要处理的人体部位是头发和上衣。</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/origin.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_src = [<span class="string">&#x27;origin.jpg&#x27;</span>]</span><br><span class="line">ace2p = hub.Module(name=<span class="string">&quot;ace2p&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set input dict</span></span><br><span class="line">input_dict = &#123;<span class="string">&quot;image&quot;</span>: img_src&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># execute predict and print the result</span></span><br><span class="line">results = ace2p.segmentation(data=input_dict)</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(result[<span class="string">&#x27;origin&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(result[<span class="string">&#x27;processed&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>因为该接口可以一次处理多张图像，所以输入是列表的形式。PaddleHub 处理后的图像会保存在 <code>ace2p_output</code> 文件夹中，给定图像的人体分析效果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/origin_processed.png" alt=""></p>
<p>在这张结果图中可以看到不同的人体部分经过语义分割后用不同的颜色进行标记，这些颜色值是官方定义的，具体的数值可以参见<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/hubdetail?name=ace2p&amp;en_category=ImageSegmentation">官方文档</a>。然后根据官方指定的人体部分颜色定义一个颜色字典</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">colors = &#123;</span><br><span class="line">    <span class="string">&#x27;background&#x27;</span>: <span class="string">&#x27;#000000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;hat&#x27;</span>: <span class="string">&#x27;#800000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;hair&#x27;</span>: <span class="string">&#x27;#008000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;glove&#x27;</span>: <span class="string">&#x27;#808000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sunglasses&#x27;</span>: <span class="string">&#x27;#000080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;upperclothes&#x27;</span>: <span class="string">&#x27;#800080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;dress&#x27;</span>: <span class="string">&#x27;#008080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;coat&#x27;</span>: <span class="string">&#x27;#808080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;socks&#x27;</span>: <span class="string">&#x27;#400000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;pants&#x27;</span>: <span class="string">&#x27;#c00000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jumpsuits&#x27;</span>: <span class="string">&#x27;#408000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scarf&#x27;</span>: <span class="string">&#x27;#c08000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;skirt&#x27;</span>: <span class="string">&#x27;#400080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;face&#x27;</span>: <span class="string">&#x27;#c00080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;left-arm&#x27;</span>: <span class="string">&#x27;#408080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;right-arm&#x27;</span>: <span class="string">&#x27;#c08080&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;left-leg&#x27;</span>: <span class="string">&#x27;#004000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;right-leg&#x27;</span>: <span class="string">&#x27;#804000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;left-shoe&#x27;</span>: <span class="string">&#x27;#00c000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;right-shoe&#x27;</span>: <span class="string">&#x27;#80c000&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面指定的颜色中，颜色均为字符串，但是实际在使用 opencv 改变颜色时，我们使用的是 cv2 的颜色格式，python 中 opencv 颜色的格式是一个三元组，例如 <code>(255, 255, 255)</code>，因此需要定义一个颜色格式转换的方法，该方法将三个两位 16 进制的字符串转换为 [0, 255] 之间的一个整数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">color_str_to_list</span>(<span class="params">color_str</span>):</span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">int</span>(color_str[<span class="number">1</span>:<span class="number">3</span>], <span class="number">16</span>), <span class="built_in">int</span>(color_str[<span class="number">3</span>:<span class="number">5</span>], <span class="number">16</span>), <span class="built_in">int</span>(color_str[<span class="number">5</span>:<span class="number">7</span>], <span class="number">16</span>)]</span><br></pre></td></tr></table></figure>
<p>在 <code>color_str_to_list</code> 函数中，返回的是一个列表（也可以使用元组），列表中包含三个元素，每一个元素使用 <code>int()</code> 函数将 16 进制的字符串转换为整数，最终得到就是 opencv 中想要的颜色值。</p>
<p>然后是变换颜色的方法，该方法输入原始图像和 PaddleHub 进行人体分析后的结果图像，同时指定需要变换颜色的人体部分，以及要改变后的颜色，返回改变颜色后的图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">change_color</span>(<span class="params">origin_img, mask_img, label, color=<span class="literal">None</span></span>):</span><br><span class="line">    label_mask = mask_img.copy()</span><br><span class="line">    result = origin_img.copy()</span><br><span class="line">    alpha = <span class="number">0.8</span>  <span class="comment"># 可修改，使之看起来更自然</span></span><br><span class="line">    label_mask[np.where((label_mask != color_str_to_list(colors[label])).<span class="built_in">any</span>(axis=<span class="number">2</span>))] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> color:</span><br><span class="line">        color = color_str_to_list(colors[label])</span><br><span class="line">    pos = np.where((label_mask == color_str_to_list(colors[label])).<span class="built_in">all</span>(axis=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> <span class="built_in">zip</span>(pos[<span class="number">0</span>], pos[<span class="number">1</span>]):</span><br><span class="line">        result[i][j] = alpha * origin_img[i][j] + (<span class="number">1</span> - alpha) * np.array(color)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>在 <code>change_color</code> 函数中，首先将原始图像和语义分割得到的人体分析结果图进行拷贝。该函数一次只处理人体中的某一个部分，例如头发，所以接着将不是头发的其他人体部分变为背景，得到只含有某个人体部分的分割图。这个分割图中的人体部分是使用的官方指定的颜色，我们想要改变该颜色，所以最后回去那些想要被改变颜色的人体部分的位置坐标，然后将这部分区域的原始图像和想要改变的颜色进行融合。可以通过改变代码中的 <code>alpha</code> 值使得融合后看起来更佳自然。</p>
<p>为了展示效果，这里再定义一个随机颜色生成方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_random_color</span>():</span><br><span class="line">    <span class="keyword">return</span> (randrange(<span class="number">0</span>, <span class="number">255</span>, <span class="number">1</span>), randrange(<span class="number">0</span>, <span class="number">255</span>, <span class="number">1</span>), randrange(<span class="number">0</span>, <span class="number">255</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>在 AIStudio 中不能像在本地一样使用 cv2 对图像进行连续展示，因此在 AIStudio 中使用 <code>matplotlib</code> 的 <code>animation</code> 进行动图展示。在以下代码中，对每一帧改变上衣和头发的颜色。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seg_main</span>():</span><br><span class="line">    img_res = cv2.imread(<span class="string">&#x27;humanseg_output/origin.png&#x27;</span>, -<span class="number">1</span>)</span><br><span class="line">    origin = cv2.imread(<span class="string">&#x27;origin.jpg&#x27;</span>, cv2.IMREAD_UNCHANGED)</span><br><span class="line">    mask = cv2.imread(<span class="string">&#x27;ace2p_output/origin_processed.png&#x27;</span>, cv2.IMREAD_UNCHANGED)</span><br><span class="line">    </span><br><span class="line">    final_list = []</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">        final = change_color(origin, mask, <span class="string">&#x27;upperclothes&#x27;</span>, get_random_color())</span><br><span class="line">        final = change_color(final, mask, <span class="string">&#x27;hair&#x27;</span>, get_random_color())</span><br><span class="line">        final = cv2.cvtColor(final, cv2.COLOR_BGRA2RGBA)</span><br><span class="line">        </span><br><span class="line">        im = plt.imshow(final, animated=<span class="literal">True</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>) </span><br><span class="line">        final_list.append([im])</span><br><span class="line">    <span class="keyword">return</span> final_list, fig</span><br></pre></td></tr></table></figure>
<p>在 <code>seg_main</code> 函数中，首先读入原始图像和人体分析后的结果图像，由于处理后的图像是 4 通道的，所以读取的时候需要为 <code>imread</code> 添加参数 <code>cv2.IMREAD_UNCHANGED</code>。这里想要处理 50 次图像，每次处理时颜色随机生成，然后将每次处理后的图像通过视频进行展示，所以使用了循环。每次循环需要调用两次 <code>change_color</code> 函数，分别改变头发和上衣的颜色。最后通过下面的代码将每一帧图像生成视频并保存。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"></span><br><span class="line">ims, fig = seg_main()</span><br><span class="line">ani = animation.ArtistAnimation(fig, ims, interval=<span class="number">500</span>, blit=<span class="literal">True</span>, repeat_delay=<span class="number">1000</span>)</span><br><span class="line">ani.save(<span class="string">&quot;movie.mp4&quot;</span>)</span><br><span class="line">HTML(ani.to_html5_video()) </span><br></pre></td></tr></table></figure>
<p>最终效果如下动图，可以看出颜色改变得还是挺自然的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/01.gif" alt=""></p>
<hr>
<h2 id="Part2-添加人脸贴纸"><a href="#Part2-添加人脸贴纸" class="headerlink" title="Part2. 添加人脸贴纸"></a>Part2. 添加人脸贴纸</h2><p>这部分主要使用的是 PaddleHub 的人脸关键点检测模型，该模型能够检测到人脸的 68 个关键点，包括人脸轮廓、左右眉毛、左右眼睛、鼻子和嘴巴。具体点的位置如下图</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/facial.jpg" alt=""></p>
<p>添加贴纸的总体思想都是一样的，这里只对其中一个进行详细说明</p>
<h3 id="耳朵贴纸实现过程"><a href="#耳朵贴纸实现过程" class="headerlink" title="耳朵贴纸实现过程"></a>耳朵贴纸实现过程</h3><p>首先猫耳的图像如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/cat.png" alt=""></p>
<ol>
<li>读取人脸图像</li>
<li>调用 PaddleHub 人脸关键点检测模型（keypoint_detection）检测 68 个人脸关键点</li>
<li>调用PaddleHub人脸检测模型（face_detection）检测人脸框</li>
<li>读取贴纸图像（4 通道 png 图像）</li>
<li>计算左眉毛最左边的点和右眉毛最右边的点，通过两点计算角度，作为倾斜角度</li>
<li>将贴纸图像旋转上一步获取的角度，同时得到旋转矩阵</li>
<li>在贴纸上取一个点作为参考点（这里取得是贴纸中鼻子的点），用旋转矩阵计算出参考点在旋转贴纸中点对应的位置</li>
<li>通过人脸框的宽度将贴纸图像进行尺寸修改，同时计算修改尺寸后参考点的位置</li>
<li>将参考点与人脸的鼻子中的一个点对应进行融合得到最终结果</li>
</ol>
<h3 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h3><p>首先导入依赖库，定义两个全局变量，LABELS 用于表示人脸的每个部分，COLORS 为了画关键点用于区分，<code>get_random_color</code> 方法用于获取随机颜色</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randrange</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_random_color</span>():</span><br><span class="line">    <span class="keyword">return</span> randrange(<span class="number">0</span>, <span class="number">255</span>, <span class="number">1</span>), randrange(<span class="number">10</span>, <span class="number">255</span>, <span class="number">1</span>), randrange(<span class="number">10</span>, <span class="number">255</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LABELS = [<span class="string">&#x27;chin&#x27;</span>, <span class="string">&#x27;left_eyebrow&#x27;</span>, <span class="string">&#x27;right_eyebrow&#x27;</span>, <span class="string">&#x27;nose_bridge&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;nose_tip&#x27;</span>, <span class="string">&#x27;left_eye&#x27;</span>, <span class="string">&#x27;right_eye&#x27;</span>, <span class="string">&#x27;top_lip&#x27;</span>, <span class="string">&#x27;bottom_lip&#x27;</span>]</span><br><span class="line">COLORS = [get_random_color() <span class="keyword">for</span> _ <span class="keyword">in</span> LABELS]</span><br></pre></td></tr></table></figure>
<p>然后调用 PaddleHub 关键点检测接口获取人脸关键点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_landmarks</span>(<span class="params">img</span>):</span><br><span class="line">    module = hub.Module(name=<span class="string">&quot;face_landmark_localization&quot;</span>)</span><br><span class="line">    result = module.keypoint_detection(images=[img])</span><br><span class="line">    landmarks = result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> landmarks</span><br></pre></td></tr></table></figure>
<p>由于在贴贴纸时需要根据脸的大小，然后对贴纸的大小进行调节，因此还需要定义获取人脸框的方法，该方法使用了 PaddleHub 中的人脸检测模型。模型返回的是左上角点坐标和右下角点坐标的形式，为了更好地处理人脸框，将其转换为左上角点，宽高的形式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_face_rectangle</span>(<span class="params">img</span>):</span><br><span class="line">    face_detector = hub.Module(name=<span class="string">&quot;ultra_light_fast_generic_face_detector_1mb_320&quot;</span>)</span><br><span class="line">    result = face_detector.face_detection(images=[img])</span><br><span class="line">    x1 = <span class="built_in">int</span>(result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;left&#x27;</span>])</span><br><span class="line">    y1 = <span class="built_in">int</span>(result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;top&#x27;</span>])</span><br><span class="line">    x2 = <span class="built_in">int</span>(result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;right&#x27;</span>])</span><br><span class="line">    y2 = <span class="built_in">int</span>(result[<span class="number">0</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;bottom&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> x1, y1, x2 - x1, y2 - y1</span><br></pre></td></tr></table></figure>
<p>为了方便对人脸的每一部分进行处理，这里定义了一个对人脸关键点进行分区的方法，该方法返回人脸每个部分的一个字典。字典的 key 为人脸关键点的每个部分的名称，值为对应的关键点列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">face_landmarks</span>(<span class="params">face_image, location_of_face=<span class="literal">None</span></span>):</span><br><span class="line">    landmarks = get_landmarks(face_image)</span><br><span class="line">    landmarks_as_tuples = [[(<span class="built_in">int</span>(p[<span class="number">0</span>]), <span class="built_in">int</span>(p[<span class="number">1</span>])) <span class="keyword">for</span> p <span class="keyword">in</span> landmarks]]</span><br><span class="line">    <span class="keyword">return</span> [&#123;</span><br><span class="line">        <span class="string">&quot;chin&quot;</span>: points[<span class="number">0</span>:<span class="number">17</span>],</span><br><span class="line">        <span class="string">&quot;left_eyebrow&quot;</span>: points[<span class="number">17</span>:<span class="number">22</span>],</span><br><span class="line">        <span class="string">&quot;right_eyebrow&quot;</span>: points[<span class="number">22</span>:<span class="number">27</span>],</span><br><span class="line">        <span class="string">&quot;nose_bridge&quot;</span>: points[<span class="number">27</span>:<span class="number">31</span>],</span><br><span class="line">        <span class="string">&quot;nose_tip&quot;</span>: points[<span class="number">31</span>:<span class="number">36</span>],</span><br><span class="line">        <span class="string">&quot;left_eye&quot;</span>: points[<span class="number">36</span>:<span class="number">42</span>],</span><br><span class="line">        <span class="string">&quot;right_eye&quot;</span>: points[<span class="number">42</span>:<span class="number">48</span>],</span><br><span class="line">        <span class="string">&quot;top_lip&quot;</span>: points[<span class="number">48</span>:<span class="number">55</span>] + [points[<span class="number">64</span>]] + [points[<span class="number">63</span>]] + [points[<span class="number">62</span>]] + [points[<span class="number">61</span>]] + [points[<span class="number">60</span>]],</span><br><span class="line">        <span class="string">&quot;bottom_lip&quot;</span>: points[<span class="number">54</span>:<span class="number">60</span>] + [points[<span class="number">48</span>]] + [points[<span class="number">60</span>]] +</span><br><span class="line">                      [points[<span class="number">67</span>]] + [points[<span class="number">66</span>]] + [points[<span class="number">65</span>]] + [points[<span class="number">64</span>]]</span><br><span class="line">    &#125; <span class="keyword">for</span> points <span class="keyword">in</span> landmarks_as_tuples]</span><br></pre></td></tr></table></figure>
<p>通常情况下，原始图像提供的贴纸都是正视的，但是人脸是有可能倾斜的，因此在贴贴纸时需要将贴纸进行相应角度的倾斜。以下两个方法分别定义了计算倾斜角度的方法和旋转贴纸的方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_angle</span>(<span class="params">point1, point2</span>):</span><br><span class="line">    x1, x2, y1, y2 = point1[<span class="number">0</span>], point2[<span class="number">0</span>], point1[<span class="number">1</span>], point2[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">180</span> / math.pi * math.atan((<span class="built_in">float</span>(y2 - y1)) / (x2 - x1))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rotate_bound</span>(<span class="params">image, angle</span>):</span><br><span class="line">    (h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">    (cX, cY) = (w / <span class="number">2</span>, h / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    M = cv2.getRotationMatrix2D((cX, cY), -angle, <span class="number">1.0</span>)</span><br><span class="line">    cos = np.<span class="built_in">abs</span>(M[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">    sin = np.<span class="built_in">abs</span>(M[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    nW = <span class="built_in">int</span>((h * sin) + (w * cos))</span><br><span class="line">    nH = <span class="built_in">int</span>((h * cos) + (w * sin))</span><br><span class="line"></span><br><span class="line">    M[<span class="number">0</span>, <span class="number">2</span>] += (nW / <span class="number">2</span>) - cX</span><br><span class="line">    M[<span class="number">1</span>, <span class="number">2</span>] += (nH / <span class="number">2</span>) - cY</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cv2.warpAffine(image, M, (nW, nH)), M</span><br></pre></td></tr></table></figure>
<p>最后定义两个方法来实现贴贴纸，<code>add_sticker</code> 需要输入原始图像文件路径，贴纸图像的文件路径，贴纸的参考点，贴纸基于人脸大小的比例，需要与贴纸参考点对应的人脸关键点部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_sticker</span>(<span class="params">img, sticker_name, base_center, ratio, face_part, point_order, extra=[<span class="number">0</span>, <span class="number">0</span>]</span>):</span><br><span class="line">    sticker = cv2.imread(sticker_name, -<span class="number">1</span>)</span><br><span class="line">    y_top_left, x_top_left, rotated = get_top_left(img, sticker, base_center, ratio, face_part, point_order, extra)</span><br><span class="line">    sticker_h, sticker_w, _ = rotated.shape</span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> y_top_left &lt; <span class="number">0</span>:</span><br><span class="line">        sticker_h = sticker_h + y_top_left</span><br><span class="line">        start = -y_top_left</span><br><span class="line">        y_top_left = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> chanel <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        img[y_top_left:y_top_left + sticker_h, x_top_left:x_top_left + sticker_w, chanel] = \</span><br><span class="line">            rotated[start:, :, chanel] * (rotated[start:, :, <span class="number">3</span>] / <span class="number">255.0</span>) + \</span><br><span class="line">            img[y_top_left:y_top_left + sticker_h, x_top_left:x_top_left + sticker_w, chanel] \</span><br><span class="line">            * (<span class="number">1.0</span> - rotated[start:, :, <span class="number">3</span>] / <span class="number">255.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_top_left</span>(<span class="params">img, sticker, base_center, ratio, face_part, point_order, extra=[<span class="number">0</span>, <span class="number">0</span>]</span>):</span><br><span class="line">    landmarks = face_landmarks(img)</span><br><span class="line">    <span class="comment"># check_if_mouth_open(img, landmarks[0])</span></span><br><span class="line">    angle = calculate_angle(landmarks[<span class="number">0</span>][<span class="string">&#x27;left_eyebrow&#x27;</span>][<span class="number">0</span>], landmarks[<span class="number">0</span>][<span class="string">&#x27;right_eyebrow&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">    nose_tip_center = base_center</span><br><span class="line">    rotated, M = rotate_bound(sticker, angle)</span><br><span class="line">    tip_center_rotate = np.dot(M, np.array([[nose_tip_center[<span class="number">0</span>]], [nose_tip_center[<span class="number">1</span>]], [<span class="number">1</span>]]))</span><br><span class="line">    sticker_h, sticker_w, _ = rotated.shape</span><br><span class="line">    x, y, w, h = get_face_rectangle(img)</span><br><span class="line">    dv = w / sticker_w * ratio</span><br><span class="line">    distance_x, distance_y = <span class="built_in">int</span>(tip_center_rotate[<span class="number">0</span>] * dv), <span class="built_in">int</span>(tip_center_rotate[<span class="number">1</span>] * dv)</span><br><span class="line">    rotated = cv2.resize(rotated, (<span class="number">0</span>, <span class="number">0</span>), fx=dv, fy=dv)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(point_order) == <span class="number">2</span>:</span><br><span class="line">        y_top_left = (landmarks[<span class="number">0</span>][face_part[<span class="number">0</span>]][point_order[<span class="number">0</span>]][<span class="number">1</span>] + landmarks[<span class="number">0</span>][face_part[<span class="number">1</span>]][point_order[<span class="number">1</span>]][<span class="number">1</span>]) // <span class="number">2</span> - distance_y - extra[<span class="number">1</span>]</span><br><span class="line">        x_top_left = (landmarks[<span class="number">0</span>][face_part[<span class="number">0</span>]][point_order[<span class="number">0</span>]][<span class="number">0</span>] + landmarks[<span class="number">0</span>][face_part[<span class="number">1</span>]][point_order[<span class="number">1</span>]][<span class="number">0</span>]) // <span class="number">2</span> - distance_x - extra[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_top_left = landmarks[<span class="number">0</span>][face_part[<span class="number">0</span>]][point_order[<span class="number">0</span>]][<span class="number">1</span>] - distance_y</span><br><span class="line">        x_top_left = landmarks[<span class="number">0</span>][face_part[<span class="number">0</span>]][point_order[<span class="number">0</span>]][<span class="number">0</span>] - distance_x</span><br><span class="line">    <span class="keyword">return</span> y_top_left, x_top_left, rotated</span><br></pre></td></tr></table></figure>
<p>基于上面两个方法可以实现任意贴纸的效果，只要指定了合适的参考点和对应点即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/02.gif" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/blog/cpp/baiduAI/03.gif" alt=""></p>
<hr>
<h2 id="Part4-更换视频背景"><a href="#Part4-更换视频背景" class="headerlink" title="Part4. 更换视频背景"></a>Part4. 更换视频背景</h2><p>由于 PaddleHub 目前仅支持图像的分割，因此要进行视频背景替换需要先将视频转换为图像帧，然后对图像进行背景替换，最后再合成视频。</p>
<p>如果视频过长，可以使用以下代码对视频进行裁剪，或者将视频中不包含人像的时间段裁剪掉，方便提取人像。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 裁剪视频</span></span><br><span class="line">!ffmpeg -i video/01.mp4 -ss 00:00:10 -c copy -t 00:00:20 video/01_cut.mp4 -loglevel quiet</span><br></pre></td></tr></table></figure>
<p><code>video/01.mp4</code> 为需要处理的视频，<code>-ss</code> 表示需要处理的起始时间点，<code>-t</code> 表示持续时间，即总共需要处理的时间。上面代码的意思就是处理视频 <code>video/01.mp4</code>，从 <code>00:00:10</code> 开始，总共处理 20 秒，处理方式是 copy，也就相当于将原视频从 <code>00:00:10</code> 开始裁剪到 <code>00:00:30</code>。</p>
<p>然后分别将前景视频和背景视频转换为图像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !ffmpeg -ss 00:00:10 -t 0:0:20 -i video/01.mp4 -r 25.0 video/01/out%4d.png\</span></span><br><span class="line">!<span class="built_in">mkdir</span> video/01</span><br><span class="line">!ffmpeg -i video/01_cut.mp4 -r 25.0 video/01/out%4d.png -loglevel quiet</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!<span class="built_in">mkdir</span> video/02</span><br><span class="line">!ffmpeg -i video/02.mp4 -r 25.0 video/02/out%4d.png -loglevel quiet</span><br></pre></td></tr></table></figure>
<p>之后创建一个文件夹用于存储结果图像集</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!<span class="built_in">mkdir</span> video/result1</span><br></pre></td></tr></table></figure>
<p>最后用 python 代码进行图像背景替换（图像融合）</p>
<blockquote>
<p>注意：这里的代码仅支持图像分割模型 1.0.0 版本，需要使用以下代码进行安装对应的版本</p>
<p>$ <code>hub install deeplabv3p_xception65_humanseg==1.0.0</code></p>
<p>另外这里我将 seg 的源码进行了修改，具体参考 <a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/370260">AIStudio</a> 项目中的代码和介绍</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">hub.logger.setLevel(<span class="string">&#x27;ERROR&#x27;</span>)</span><br><span class="line">module = hub.Module(name=<span class="string">&quot;deeplabv3p_xception65_humanseg&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">blend_images</span>(<span class="params">fore_image, base_image, ratio, pos=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将抠出的人物图像换背景</span></span><br><span class="line"><span class="string">    fore_image: 前景图片，抠出的人物图片</span></span><br><span class="line"><span class="string">    base_image: 背景图片</span></span><br><span class="line"><span class="string">    ratio: 调整前景的比例</span></span><br><span class="line"><span class="string">    pos: 前景放在背景的位置的，格式为左上角坐标</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(base_image, <span class="built_in">str</span>):</span><br><span class="line">        bg_img = cv2.imread(base_image)  <span class="comment"># read background image</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bg_img = base_image</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(fore_image, <span class="built_in">str</span>):</span><br><span class="line">        fg_img = cv2.imread(fore_image, -<span class="number">1</span>)  <span class="comment"># read foreground image</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fg_img = fore_image</span><br><span class="line">    height_fg, width_fg, _ = fg_img.shape  <span class="comment"># get height and width of foreground image</span></span><br><span class="line">    height_bg, width_bg, _ = bg_img.shape  <span class="comment"># get height and width of background image</span></span><br><span class="line">    <span class="keyword">if</span> ratio &gt; (height_bg / height_fg):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;ratio is too large, use maximum ratio <span class="subst">&#123;(height_bg / height_fg): <span class="number">.2</span>&#125;</span>&#x27;</span>)</span><br><span class="line">        ratio = <span class="built_in">round</span>((height_bg / height_fg), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> ratio &lt; <span class="number">0.1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ratio &lt; 0.1, use minimum ratio 0.1&#x27;</span>)</span><br><span class="line">        ratio = <span class="number">0.1</span></span><br><span class="line">    <span class="comment"># if no pos arg input, use this as default</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pos:</span><br><span class="line">        pos = (height_bg - <span class="built_in">int</span>(ratio * height_fg), width_bg // <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    roi = bg_img[pos[<span class="number">0</span>]: pos[<span class="number">0</span>] + <span class="built_in">int</span>(height_fg * ratio), pos[<span class="number">1</span>] : pos[<span class="number">1</span>]+<span class="built_in">int</span>(width_fg*ratio)]</span><br><span class="line">    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(fore_image, <span class="built_in">str</span>):</span><br><span class="line">        fore_image = Image.<span class="built_in">open</span>(fore_image).resize(roi.shape[<span class="number">1</span>::-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fore_image = cv2.resize(fore_image, roi.shape[<span class="number">1</span>::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图片加权合成</span></span><br><span class="line">    scope_map = np.array(fore_image)[:, :, -<span class="number">1</span>] / <span class="number">255</span></span><br><span class="line">    scope_map = scope_map[:, :, np.newaxis]</span><br><span class="line">    scope_map = np.repeat(scope_map, repeats=<span class="number">3</span>, axis=<span class="number">2</span>)</span><br><span class="line">    res_image = np.multiply(scope_map, np.array(fore_image)[:, :, <span class="number">2</span>::-<span class="number">1</span>]) + np.multiply((<span class="number">1</span> - scope_map), np.array(roi))</span><br><span class="line"></span><br><span class="line">    bg_img[pos[<span class="number">0</span>]: pos[<span class="number">0</span>] + roi.shape[<span class="number">0</span>], pos[<span class="number">1</span>]: pos[<span class="number">1</span>] + roi.shape[<span class="number">1</span>]] = np.uint8(res_image)[:, :, ::-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> bg_img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seg</span>(<span class="params">image, back_img_name</span>):</span><br><span class="line">    input_dict = &#123;<span class="string">&quot;image&quot;</span>: [image]&#125;</span><br><span class="line">    result, seg_img = module.segmentation(data=input_dict)</span><br><span class="line">    seg_img = seg_img.astype(np.uint8)</span><br><span class="line">    img = blend_images(seg_img, back_img_name, <span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">fore_path = <span class="string">&#x27;video/01/&#x27;</span></span><br><span class="line">back_path = <span class="string">&#x27;video/02/&#x27;</span></span><br><span class="line"></span><br><span class="line">fore_lists = <span class="built_in">sorted</span>([fore_path + name <span class="keyword">for</span> name <span class="keyword">in</span> os.listdir(fore_path)])</span><br><span class="line">back_lists = <span class="built_in">sorted</span>([back_path + name <span class="keyword">for</span> name <span class="keyword">in</span> os.listdir(back_path)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(back_lists)):</span><br><span class="line">    img = seg(fore_lists[i], back_lists[i])</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;video/result1/&#x27;</span> + <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>&#x27;</span>.zfill(<span class="number">4</span>) + <span class="string">&#x27;.png&#x27;</span>, img)</span><br></pre></td></tr></table></figure>
<p>因为是每一帧每一帧进行处理的，所以这个过程非常非常漫长。。。</p>
<p>如果直接合成的视频是没有音频的，因此为了效果，先提取原始视频中的音频，然后再将音频与该生成视频进行融合。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取音频</span></span><br><span class="line">!ffmpeg -i video/01_cut.mp4 video/3.mp3 -loglevel quiet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像转换为视频</span></span><br><span class="line">!ffmpeg -f image2 -i video/result/%4d.png -r 25 video/result.mp4 -loglevel quiet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加音频合成视频</span></span><br><span class="line">!ffmpeg -i video/result.mp4 -i video/3.mp3 -vcodec copy -acodec copy video/final.mp4 -loglevel quiet</span><br></pre></td></tr></table></figure>
<p>最后为了在 AIStudio 中展示视频，我将视频传到了 github 作为 CDN，然后通过 IPython 的 Video 进行展示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 展示视频</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML, Video</span><br><span class="line"><span class="comment"># HTML(&#x27;&lt;center&gt;&lt;video controls autoplay src=&quot;video/01_cut.mp4&quot; width=61.8%/&gt;&lt;/center&gt;&#x27;)</span></span><br><span class="line">Video(<span class="string">&quot;https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/video/01_cut.mp4&quot;</span>, width=<span class="number">960</span>, height=<span class="number">600</span>)</span><br></pre></td></tr></table></figure>
<center>
    <video controls src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/video/final.mp4" width=100%/>
</center>

<h2 id="相关项目与其他内容"><a href="#相关项目与其他内容" class="headerlink" title="相关项目与其他内容"></a>相关项目与其他内容</h2><ul>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/370260">PaddleHub 人像分割创意赛 —— JUST FOR FUN</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/402824">PaddleHub：人脸检测主题创意赛</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/414952">PaddleHub：人脸检测主题创意赛贴纸视频版</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://busyboxs.github.io">Busyboxs</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://busyboxs.github.io/blogs/98b64d33/">https://busyboxs.github.io/blogs/98b64d33/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://busyboxs.github.io" target="_blank">Busyboxs</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/cpp/">cpp</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/blogs/d6dbbf06/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">(简单调用篇 10) 地标识别 - C++ 简单调用</div></div></a></div><div class="next-post pull-right"><a href="/blogs/e5bd0fbd/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/cpp.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">chrono 标准库</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/blogs/cb803aa6/" title="(简单调用篇 03) 动物识别 - C++ 简单调用"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-07</div><div class="title">(简单调用篇 03) 动物识别 - C++ 简单调用</div></div></a></div><div><a href="/blogs/3f2fcf2e/" title="(基础篇 04) C++ base64 编解码原理及实现"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-25</div><div class="title">(基础篇 04) C++ base64 编解码原理及实现</div></div></a></div><div><a href="/blogs/dea770b9/" title="（基础篇 01）在控制台创建对应的应用"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-25</div><div class="title">（基础篇 01）在控制台创建对应的应用</div></div></a></div><div><a href="/blogs/6956883f/" title="(简单调用篇 09) 货币识别 - C++ 简单调用"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-07</div><div class="title">(简单调用篇 09) 货币识别 - C++ 简单调用</div></div></a></div><div><a href="/blogs/49f400d2/" title="（基础篇 03）C++ 获取 access token"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-25</div><div class="title">（基础篇 03）C++ 获取 access token</div></div></a></div><div><a href="/blogs/957d8cb8/" title="(简单调用篇 07) 菜品识别 - C++ 简单调用"><img class="cover" src="https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/covers/baiduAI.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-07</div><div class="title">(简单调用篇 07) 菜品识别 - C++ 简单调用</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#PaddleHub-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">PaddleHub 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part1-%E5%8F%98%E6%8D%A2%E4%BA%BA%E4%BD%93%E9%83%A8%E5%88%86%E7%9A%84%E9%A2%9C%E8%89%B2"><span class="toc-number">2.</span> <span class="toc-text">Part1. 变换人体部分的颜色</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part2-%E6%B7%BB%E5%8A%A0%E4%BA%BA%E8%84%B8%E8%B4%B4%E7%BA%B8"><span class="toc-number">3.</span> <span class="toc-text">Part2. 添加人脸贴纸</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%80%B3%E6%9C%B5%E8%B4%B4%E7%BA%B8%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">耳朵贴纸实现过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.2.</span> <span class="toc-text">代码详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part4-%E6%9B%B4%E6%8D%A2%E8%A7%86%E9%A2%91%E8%83%8C%E6%99%AF"><span class="toc-number">4.</span> <span class="toc-text">Part4. 更换视频背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE%E4%B8%8E%E5%85%B6%E4%BB%96%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text">相关项目与其他内容</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/busyboxs/CDN@latest/img/archive_img.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By Busyboxs</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">❤🦋Stay foolish. Stay hungry.🦋❤</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="爱你哟,好好学习，天天向上,Stay hungry. Stay foolish.,✨✨✨,🎈🎈🎈,🎮🎮,♥♥♥♥,🏐🏐,🪂🪂" data-fontsize="10px" data-random="true" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>